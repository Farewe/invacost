---
title: "The INVACOST R Package: Global Costs of Biological Invasions"
author: "INVACOST team"
date: "20/04/2020"
output:
  html_document:
    df_print: kable
    toc: yes
    toc_float: true
  github_document:
    toc: true
    toc_depth: 2
---

```{r hiddenload, echo=FALSE, results="hide", message=FALSE}
# # knitr::opts_chunk$set(warning=FALSE,
#                       message=FALSE)
library(invacost)
data(invacost)

```

# WARNING

This page represents work in progress and no third parties are allowed to use
it under any circumstances. For more information, please write to 
leroy.boris@gmail.com, christophe.diagne@u-psud.fr and franck.courchamp@u-psud.fr

# Introduction 

The INVACOST R package provides the INVACOST database in R with several 
functions to analyse economic costs of invasive species. 

There are two main methods developed in this package to estimate the costs
associated
to biological invasions.

 - The first approach consists in calculating the *raw costs* (i.e., observed
 costs) that occurred over
 specific intervals of time. From this approach you can obtain the *observed*
 cumulated and 
 average annual costs of biological invasions for different time intervals.  
 This approach is generalisable to any subset of the INVACOST database,
 regardless of data quantity. However, it does not account for the temporal dynamics
 of costs, and may thus underestimate the costs of invasions, especially for
 recent years for which we likely have incomplete data.
 
 - The second approach consists in **estimating** the long-term trend in annual cost 
 values with an ensemble modelling approach. Because it includes the dynamic 
 nature of cost values, it is probably the most robust approach to estimate 
 average annual costs. However, it requires more data and for data-poor cases it
 will not work or provide inadequate results. We fit several models because the
 trend of costs over time is not necessarily linear.
 This approach requires decisions about  models to keep or remove, on the basis
 of the quality of model fit, and/or of our *a priori* assumptions. Note that this
 modelling approach is not designed for extrapolations because there is no
 certainty that the underlying factors of costs will have similar trends in the
 future.
 
 
# Installation
The easiest method to install the package for now is to install it directly from
github with the following command line (requires the package devtools).

**DOES NOT WORK UNTIL THE PACKAGE IS RELEASED PUBLICLY ON GITHUB**

``` {r install, eval = FALSE}
install.packages("devtools")
devtools::install_github("Farewe/invacost")
```

However, for as long as the package is in embargo, you have to install it 
manually from the .tar.gz file. Before you do that, install the following 
packages:

```{r i1, eval = FALSE}
install.packages(c("dplyr", "earth", "mgcv", "quantreg", "scales"))
```

Then, install the package from the .tar.gz file (do not extract it,
install from the raw .tar.gz).

# Changes to the package

## August 2020

- Andrew Kramer joined the dev team

- Updated all statistical methods in `costTrendOverTime` to better address 
statistical issues with the data, and notably heteroskedasticity.

- **Important**: new versions of the stats should no longer require you to
tweak model parameters. Please consider recalibrating models **WITHOUT**
GAM and MARS arguments.

- Added a new model to mode the trend of costs over time, namely robust
regressions (addition by Andrew Kramer). Robust regression handle natively
data heteroskedasticity & reduce the weight of outliers on the regression.

- Some new features have been added in `calculateRawAvgCosts()`, e.g. a table
in the output list with all values per individual years, with number of
estimates.

- Added plotting features/capabilities

- Updated invacost data to v2.1. Added a column in invacost to filter out versions
of the database.


## April 2020
For those of you who tried the earlier versions of the package:

- Many bugs arose when working on small subsets of INVACOST. Most of them have
been corrected. 

- Graphics are no longer included in the functions. They are not provided as
stand-alone generic function (i.e. type `plot(your.object)` and you will get
the same graphs as before). They are easier to customise if you are familiar 
with ggplot2.

- New information has been added in outputs of functions, e.g. the number of 
unique estimates used to compute values.

- Lots of minor changes / quality of life improvement.

- Minor corrections to the database (mainly typos)


# Basic steps to get started
## How to load the data in R?

```{r i2, cache = TRUE}
library(invacost)
data(invacost)
```
The database is now loaded in R memory under a very original name: `invacost`.

```{r i3, cache = TRUE}
# Number of rows (cost estimates)
nrow(invacost)
# Number of columns (database fields)
ncol(invacost)
```

There are `r ncol(invacost)` fields in the INVACOST database, and I strongly 
recommend you get familiarised with them by inspecting them individually and
reading the paper describing the database (and its fields) available here:
`link to be added when available ¯\_(ツ)_/¯`.

## How to distinguish between invacost v1 and subsequent versions?

INVACOST v1 only includes the original data we had back in November 2019.
Later additions to INVACOST have versions such as V2 and V2-1. Later versions
are supposed to include all data from V1 to V2-1. If you want to roll back to
earlier versions of INVACOST, use the column `version` to **remove** recent
entries. 

*NOTE*: YOU SHOULD NOT REMOVE OLDER ENTRIES! They are also part of 
recent versions. e.g. if you want to use version v2-1, use all entries of the 
database, not those only with "V2-1"!


Here is an example on how to roll back to V1 or V2:
```{r rollback, cache = TRUE}
# Versions
unique(invacost$Version)

# Rollback to V1
invacost_V1 <- invacost[-which(invacost$Version %in% c("V2", "V2-1")), ]
nrow(invacost_V1)

# Rollback to V2
invacost_V2 <- invacost[-which(invacost$Version %in% "V2-1"), ]
nrow(invacost_V2)

```


## Where are the economic values I should use?

There are several fields that contain economic values (they generally contain
`cost` in their names), but you probably won't
need most of them. Indeed, we stored raw information from the papers, but this
raw information is often difficult to compare because of
different currencies, different years (inflation) and different periods of time
(e.g. 1 year vs 10 years). Therefore, we standardised economic values into 
annual cost values in 2017 US$ with two different methods. We recommend you 
use one of these two standardised cost columns:

 - `Cost_estimate_per_year_2017_USD_exchange_rate`: Annual cost estimate in 
 US$ 2017 based on exchange rate
 - `Cost_estimate_per_year_2017_USD_PPP`: Annual cost estimate in 
 US$ 2017 based on purchasing power parity (PPP)

The second method is probably more robust to provide equitable estimations 
between countries, but PPP was not available for all countries and all years, so
oftentimes it could not be estimated. Therefore, to avoid data exclusion, we 
generally tend to focus on exchange rate since it is available for most country
after 1960. 

Therefore, in the following sections we will always use the same column for cost 
values: `Cost_estimate_per_year_2017_USD_exchange_rate`.


There is a small number of costs for which we could not derive these estimates
(e.g. studies that lacked useful information of the periods over which
costs occurred), so we have to exclude them of our analyses.

```{r z4, cache = TRUE}
if(any(is.na(invacost$Cost_estimate_per_year_2017_USD_exchange_rate)))
{
  invacost <- invacost[-which(is.na(invacost$Cost_estimate_per_year_2017_USD_exchange_rate)), ]
}

# Number of rows (cost estimates)
nrow(invacost)
```

## How do we filter out unreliable costs?

You have to be aware of the limitations of such a database. This database is
the most up-to-date and comprehensive compilation of both the published
and grey literature on the 
economic costs of biological invasions. Therefore, it includes sound estimations
of economic costs of invasive species, with detailed sources and reproducible 
methodology; but it also includes unsourced and irreproducible "*guestimates*".
Therefore, we want to apply filters on the database to avoid as much as possible
the unreliable economic cost estimates. Furthermore, the database includes both
observed and predicted costs, so depending on our objectives we may or may not
want to filter out potential costs.

- **Reliability**: There is a standard field in the database called `Method_reliability`,
which provides a simple yet objective evaluation of the reliability of cost 
estimates. It uses the following decision tree:
`r knitr::include_graphics("./Readme_files/figure-html/reliability.png")`
Red means categorised as unreliable, green means categorised as reliable. This
`Method_reliability` descriptor has some limitations. The most important one 
is that we decided to not evaluate the methodology for peer-reviewed articles 
and official reports. This choice was based on experiments where we identified
strong divergence in reliability decisions between different members of the 
INVACOST team. We also identified that depending on the study objective, 
different decisions about reliability could be made. Therefore, this
`Method_reliability` descriptor should be considered as a first approximation of 
cost reliability, and you should decide whether or not you want to eliminate 
papers on the basis of the lack of reproducibility of their methodologies.
To do that, take time to investigate the `Details` field (especially for cost
values that you deem suspiciously high) and potentially go back to the source to
make your decision. For an example on how to do that, take a look at the 
"Determining cost estimate reproducibility" section in 
[Bradshaw et al. 2016](https://www.nature.com/articles/ncomms12986#Sec8).

```{r filt1}
unique(invacost$Method_reliability)
```

- **Observed vs. Potential costs**: The `Implementation` field in the database
documents whether the costs correspond to *Observed* or *Potential* costs. 
Choosing to keep one or both of them depends on your study objectives. 
In addition, costs can also be based on
direct observations or estimations, or can be based on extrapolations: this is 
documented in the `Acquisition_method` field. Extrapolation does 
not necessarily mean *Potential*: some Observed costs may have been extrapolated
from a reduced spatial extent. Below is a table showing the number of cases
of extrapolations and reports/estimation for *Observed* and *Potential* costs.  As 
you can see, the majority of Observed costs are based on reports / 
estimations; yet a few are based on extrapolations.
```{r obs}
table(invacost$Acquisition_method, invacost$Implementation)
```


For the rest of this tutorial, we will be working only on costs categorised as
"High" in `Method_reliability` and "Observed" in `Implementation`:

```{r filter1}
invacost <- invacost[which(invacost$Method_reliability == "High"), ]
invacost <- invacost[which(invacost$Implementation == "Observed"), ]

# Number of rows after filtering
nrow(invacost)
```

- **Inadequate time period information**: Some studies omitted to provide time 
periods, which can cause tremendous biases when analysing the temporal trends of
costs. Sometimes, this is not problematic as we can safely guess when costs 
occurred (see next section). However, other times, costs spread over 10+ and
sometimes 100+ years can be presented
as occurring over a single year or require highly speculative guesses about when 
they occurred. As a general rule, it is much easier and safer to estimate the
ending year than the starting year. Therefore, we recommend to remove all 
estimates that are known to occur over more than 1 year with no information on
the starting date whatsoever, and also remove the remaining estimates for which
it is not possible to safely estimate if they occurred over a single or multiple 
years. 

```{r filter2}
# Uncertain starting periods
uncertain.starts <- invacost[which(invacost$Time_range == "Period" &
                                     is.na(invacost$Probable_starting_year)), ]
# Number of estimates without adequate information about starting year
nrow(uncertain.starts)

# No info about whether cost was annual or over a period
unknown.periods <- invacost[which(is.na(invacost$Time_range)), ]
# Number of estimates without adequate information about starting year
nrow(uncertain.starts)

# Applying the filter
invacost <- invacost[-which(invacost$Cost_ID %in% c(uncertain.starts$Cost_ID,
                                                    unknown.periods$Cost_ID)), ]
# Number of rows after filtering
nrow(invacost)
```

## How do I know when costs occurred? 

A crucial aspect in analysing cost values is to know the periods of time
over which costs have occurred. Indeed, knowing the period over which a cost occurred
allows to derive cumulative costs and to estimate average annual costs; it also 
enables temporal analyses of costs.  
We have stored information on the periods of time over which cost occurred
in two fields: `Probable_starting_year` and `Probable_ending_year`.

However, this information was not readily available in a
substantial portion of the papers we compiled in the database: for
`r nrow(invacost[which(is.na(invacost$Probable_starting_year) |
                      is.na(invacost$Probable_ending_year)), ])` out of 
`r nrow(invacost)` papers (`r round(nrow(invacost[which(is.na(invacost$Probable_starting_year) |
                      is.na(invacost$Probable_ending_year)), ]) / nrow(invacost), 3) * 100`
                      % of papers), this information was not available for at
least one of the two columns.
                      
Therefore, for papers for which it was not available, we made 
educated guesses on the probable starting and ending years, on the basis of a 
set of rules we decided for our main paper (*link to be added when the paper is 
published*). These educated guesses were based on conservative rules
(e.g., if no duration information was provided,
then the impact was reported of one year only). These estimated starting and
ending years are available in
two new fields in the database called `Probable_starting_year_low_margin` and 
`Probable_ending_year_low_margin`.


As it stands now, each cost has a starting and an ending year, and schematically
it looks like this:



| Cost ID    | Species      | Annual Cost | Starting  year |  Ending year |
|------------|:--------------|--------:|-----------:|--------:|
| 1          | Sp 1         | 100    | 1998      | 2001   |
| 2          | Sp 2         | 15     | 2005      | 2007   |
| 3          | Sp 3         | 3      | 1981      | 1981   |

However, to properly analyse the temporal trends of costs, we need to *expand* 
it, to make it look like this:

| Cost ID    | Species       | Annual Cost | Year |
|------------|:--------------|------------:|-----:|
| 1          | Sp 1          | 100         | 1998 |
| 1          | Sp 1          | 100         | 1999 |
| 1          | Sp 1          | 100         | 2000 |
| 1          | Sp 1          | 100         | 2001 |
| 2          | Sp 2          | 15          | 2005 |
| 2          | Sp 2          | 15          | 2006 |
| 2          | Sp 2          | 15          | 2007 |
| 3          | Sp 3          | 3           | 1981 | 


To do this, we use the function `expandYearlyCosts`, to
which we provide the starting and ending year columns. It will store the
years over which economic costs have occurred in a column named `Impact_year`.

```{r i2y, cache = TRUE}
# Expanding and formating the database
db.over.time <- expandYearlyCosts(invacost,
                                  startcolumn = "Probable_starting_year_low_margin",
                                  endcolumn = "Probable_ending_year_low_margin")
# Let's see some columns
head(db.over.time[, c("Cost_ID", "Species",
                      "Cost_estimate_per_year_2017_USD_exchange_rate",
                      "Impact_year")])
```

## How complete is our economic data?

It is impossible to evaluate the absolute degree of completeness of our 
INVACOST - we know that we lack data for many taxonomic groups (e.g. plants are
currently underrepresented) and many places around the earth (most cost data is
located in North America and Europe). You have to be aware of these 
potential biases and remember them when interpreting data/analyses.


There is, however, a temporal bias that we can at least evaluate. Indeed, we can
expect that there is delay between the economic impact of an
invasive species, and the time at which people will start estimating the 
value of the impact, and then publish it in a report or journal.

We can grasp an idea of this delay by looking at the difference between 
`Impact_year` and `Publication_year` in the expanded database, `db.over.time`.



```{r lag1, cache=TRUE, fig.height = 4, fig.width = 12}
# Calculating time lag
db.over.time$Publication_lag <- db.over.time$Publication_year - db.over.time$Impact_year

# Make a nice boxplot of the time lag
ggplot(db.over.time,
       aes(y = Publication_lag)) +
  geom_boxplot(outlier.alpha = .2) +
  ylab("Publication lag (in years)") + 
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text = element_text(size = 16),
        axis.title = element_text(size = 18)) +
  scale_y_continuous(breaks = c(-25, 0, 25, 50, 75, 100),
                     labels = c(-25, 0, 25, 50, 75, 100)) +
  xlab("") +
  coord_flip()
```

*Note that the few occurrences of publications before economic impacts (negative
lag) corresponded to planned budgets over specific periods expanding beyond 
the publication year.*

Our suggestion is to use the quartiles of publication lag as an indication of 
cost data completeness.

The first quartile indicates the delay to reach 25% completeness; 
the median indicates the delay to reach 50% completeness; and the third quartile
indicates the delay to reach 75% completeness.

Let's see these delays in practice:

```{r lag4.1, cache=TRUE}
quantiles <- quantile(db.over.time$Publication_lag, probs = c(.25, .5, .75))
quantiles
```



The median delay between impact and publication of impact was 
**`r median(db.over.time$Publication_lag)` years**. In other words, **for the last 
`r median(db.over.time$Publication_lag)` years, we can expect to have less than 50% 
of the economic impacts**. 

Likewise, we can say it takes approximately `r quantiles[1]` years to have 25% of the 
economic data for any year, and `r quantiles[3]` years to reach at least 75% of 
economic data.

Hence, any analysis on recent years will be based on incomplete data and is 
highly likely to provide an underestimation of actual costs.

It is up to you to determine how you desire to include this information in your 
analyses; here, we will provide examples of how we suggest doing that.


One question that may arise for people working on specific subsets of the 
database (e.g., only one taxon or one country) is whether you should evaluate 
the time lag on your subset. *I would recommend to avoid that, because your 
subset may be too incomplete to provide a decent estimation of the time lag.
**Therefore, I would suggest to evaluate the time lag only on the global dataset, 
as we did here.***




# Calculate raw/observed costs of invasions

## Basic usage
The first method to analyse economic costs of invasive species consists in
calculating the observed cumulative and average costs over a specific period 
of time, or at different time intervals.

We implemented this method in the function `calculateRawAvgCosts`. It will 
calculate the cumulative and average costs for the entire period, as well as
for different time intervals (by default, 10-year intervals).

```{r raw1, cache=TRUE}
raw.costs <- calculateRawAvgCosts(db.over.time,
                                   maximum.year = 2020)
```

We can get a summary of the results by typing the name of the object in the 
console
```{r raw2, cache=TRUE}
raw.costs
```

And we can have a graphical output with:
```{r raw3, cache=TRUE}
plot(raw.costs)
```

This graph represents the observed annual costs of biological invasions over 
time. Points are total annual costs for every year (i.e., all individual costs
for a specific year are summed). Horizontal bars represent the average annual
cost for a specific interval of time (here, 10-year intervals). Notice how 
average annual costs can sometimes be driven by a limited number of high-cost 
years. The dashed line connects average annual cost of each time interval at mid-years
(black dots). The horizontal dotted line represents the average cost over the 
entire period.

The average annual cost seems to suspiciously drop for the most recent years -
most likely because of the time lag between the occurrence of a cost and its
reporting. Therefore, caution would be required in interpreting the values of 
most recent years.

A good way to illustrate this issue would be to look at the number of estimates
per year.

```{r raw3.}
ggplot(raw.costs$cost.per.year,
       aes(x = year, y = number_estimates)) +
  geom_point() +
  ylab("Number of estimates") +
  xlab("Year") +
  theme_minimal()
```

We can see that the number of estimates increases exponentially, but this
increase seems to drops after 2013.

We can refine this graph to add the relationship with annual costs:

```{r raw3..}
ggplot(raw.costs$cost.per.year,
       aes(x = year, y = number_estimates,
           size = cost)) +
  geom_point() +
  ylab("Number of estimates") +
  xlab("Year") +
  theme_minimal()
```


Use this information, in combination with the quantiles of
completeness calculated above, to decide how you want to interpret the last years,
and whether or not you want to omit them in further analyses. Remember that
no choice will be objective here, but also that objectivity does not emerge from
the absence of choice (keeping biased data is a choice in itself). 
I would recommend a transparently explained choice, along with e.g. a
sensitivity analysis.


We can access the content of the output object with
```{r raw3.1, cache=TRUE}
str(raw.costs)
```

Notice that the expanded database used to calculate costs has been stored in
the object, in a slot called `cost.data`. 
This is especially important for reproducibility: in case you
decide to publish your work, you can provide this R object which has the exact 
copy of your specific version/filters of the database.

There are also some other important elements in this object:

 - `parameters`: provides arguments you chose and basic information about your
 dataset
 - `year.breaks`: your time intervals
 - `cost.per.year`: costs for every year in the data with number of estimates
 - `average.total.cost`: contains cumulative and average annual costs for the
 entire time period
 - `average.cost.per.period`: contains cumulative and average annual costs
 for each time interval
 
You can access each element with the `$` sign; for example for the costs
for all time intervals:

```{r raw3.2, cache=TRUE}
raw.costs$average.cost.per.period
```

## Customising parameters

There are two main parameters to customize:

 - **beginning** (`minimum.year`) and **ending year** (`maximum.year`) of the entire 
 time period. For example in our
 analyses for the main paper we chose to start at 1970, because data for the
 1960s are scarce and uncertain.
```{r raw4, cache=TRUE}
raw.costs2 <- calculateRawAvgCosts(db.over.time,
                                  minimum.year = 1970,
                                  maximum.year = 2017)
raw.costs2
```
The function tells you how many values were removed from the 
dataset because they were outside the 1970-2017 time periods. 2017 was chosen
as the default value as it was the last year for INVACOST V1.

 - **time intervals**: set them with the arguments `year.breaks`, where you specify
 the starting year of each interval. For example, if your specify 
 `year.breaks = c(1970, 1980, 1990, 2000, 2010, 2017)`, then intervals will be
 [1970-1979], [1980-1989], [1990-1999], [2000-2009], [2010-2017]
 
```{r raw4.1, cache=TRUE}
# let's plot 20-year intervals
raw.costs3 <- calculateRawAvgCosts(db.over.time,
                                  minimum.year = 1960,
                                  maximum.year = 2017,
                                  year.breaks = seq(1960, 2017, by = 20))
plot(raw.costs3)
```

## Customising graphs

There are two methods to customise graphs. 

- The first one is to use the 
standard ggplot produced by the package and adding things or changing 
parameters. This method is easy to implement but you cannot change everything
(e.g. adjust the colors/shapes of points is not possible). This is what we
will see here. See the help here: `?plot.invacost.rawcost`

- The second one is to make your own ggplot from the output object. It is 
more difficult to implement if you are not familiar with graphs in R - but it
will be fully customisable. Take a look at the scripts from our main paper 
(`link to be added when available ¯\_(ツ)_/¯`) to see how to that.


There are two base plots provided with the package; you have already seen the 
default, and here is another one:

```{r raw5, cache=TRUE}
plot(raw.costs,
     plot.type = "bars")
```

You can also remove the log10 scale:

```{r raw5.1, cache=TRUE}
plot(raw.costs,
     plot.type = "bars",
     cost.transf = NULL)
```

To customise parameters using the standard ggplot produced by the package,
you will have to set the argument `graphical.parameters = "manual"`.

```{r raw5.2, cache=TRUE}
# Store the plot in object p1 to customize it afterwards
p1 <- plot(raw.costs,
           graphical.parameters = "manual")

# Show the graph in its initial state
p1
```

You see that when we specify `graphical.parameters = "manual"`, all the cosmetic choices
we made in the function are removed. You can now choose them by yourself; here 
is a starting point:
```{r raw5.3, cache=TRUE}
# Customize p1 now
p1 <- p1 +
  xlab("Year") + 
  ylab("Average annual cost of invasions in US$ millions") +
  scale_x_continuous(breaks = raw.costs$year.breaks) + # X axis breaks
  theme_bw() + # Minimal theme
  scale_y_log10(breaks = 10^(-15:15), # y axis in log 10 with pretty labels
                labels = scales::comma) +
  annotation_logticks(sides = "l") # log10 tick marks on y axis

# Let's see how it goes
p1
```

Your turn to play with graphs now!

# Estimate the average annual cost of invasions

The second method we provide in the package consists in estimating the long-term
trend in annual cost with different modelling techniques. In other words, we fit
a model to predict costs as a function of years. Then, we can inspect the 
different models and the shapes of cost trends over time, and grasp an idea
of dynamics of invasion costs.

This approach requires more data than the raw approach and for data-poor cases it
will not work or provide inadequate results. 


## Correction for data incompleteness due to publication lag

Because the average annual economic cost of invasive species will be determined
by the trend over time, we should consider applying a correction to ‘incomplete’ 
years. 

This is no simple decision and your choice will have to be justified.

There two different methods we can apply here, either independently or in
combination.

- The first method consists in applying a threshold of incompleteness to remove
the most incomplete years. For example, remove 
from calibration all years with < 75% of data; threshold = `r quantiles[3]` years.

- Another possibility includes weighting incomplete years to reduce their importance in
the estimation of average annual costs of invasions. 
This approach can be justified if we do not want to underestimate the average annual
cost of invasions. However, be advised that reviewers may disagree with your 
choices of weights, so justify them carefully, and consider analysing the 
difference with / without weights.


### Example of a vector of incompleteness weights 

An example
to reduce the negative impact of the incompleteness of recent years
would be to apply weights proportional to their degree of incompleteness. For
example, apply the following set of rules:
• completeness ≤ 25%: exclusion 
• 25% < completeness ≤ 50%: weight = 0.25 
• 50% < completeness ≤ 75%: weight = 0.50 
• completeness > 75%: weight = 1


Remember that we stored quantiles in the beginning of this tutorial, so we can
access them now to know to what years they correspond:

```{r incomp}
quantiles
```

In the next lines of code we will create a vector of weights for each year, which we
can provide to the function later on.

```{r lag5, cache = TRUE}
# Creating the vector of weights
year_weights <- rep(1, length(1960:2017))
names(year_weights) <- 1960:2017

# Assigning weights
# Below 25% the weight does not matter because years will be removed
year_weights[names(year_weights) >= (2017 - quantiles["25%"])] <- 0
# Between 25 and 50%, assigning 0.25 weight
year_weights[names(year_weights) >= (2017 - quantiles["50%"]) &
               names(year_weights) < (2017 - quantiles["25%"])] <- .25
# Between 50 and 75%, assigning 0.5 weight
year_weights[names(year_weights) >= (2017 - quantiles["75%"]) &
               names(year_weights) < (2017 - quantiles["50%"])] <- .5

# Let's look at it
year_weights
```




## Assumptions

As we fit several models based on different techniques, we suggest to define
rules for deciding which model(s) should be finally considered.

Here are examples of rules:

  - statistical information about the quality of the fit:
adequate error estimations for models, sensitivity to outliers, the Root Mean
Square Error (RMSE - lower is generally better but it may also 
be indicative of model overfitting), inspection of model terms and residuals
  
  - simplicity: for models with similar performance, we prefer the models with 
less assumptions
  
  - a qualitative rationale on the probable shape of trends over time: because 
of the exponential increase in the number of invasive species globally (Seebens 
et al. 2017), we expect the long-term temporal trend over time to be either 
increasing or stabilising, but not decreasing. Hence, we assume that a model 
describing a decreasing trend in recent years (i.e., for years lower than the
75% completeness threshold) would indicate an effect of the lack of data for 
recent years. 

## Models included in the ensemble modelling

There are several models included in the function. All models are calibrated
with cost data as the response variable and time as predictive variable. Note
that the economic data have statistical issues typical to *econometric* data:
heteroskedasticity, temporal autocorrelation and outliers. Therefore, our choice of 
modelling methods was driven by methods relatively robust to such issues.

**Note: when using the package, please cite the individual model packages.
Update citations with your package versions! To do that
type for example `citation(earth)` in R**

 - **Ordinary least square regressions** (hereafter called OLS, R package `stats`,
 function `lm`).
 OLS regressions are the classical regression methods used in statistics. 
 Coefficient estimates should be relatively robust to heteroscedasticity &
 temporal autocorrelation but not to outliers. However, error estimates need to
 be corrected, so we used the Heteroskedasticity and Autocorrelation Consistent 
 covariance matrix estimations from the R package
 `sandwich` (Andrews 1991, Zeileis 2004), and we 
 used the function `coeftest` from package `lmtest` (Zeileis & Hothorn 2004) to test for the significance
 of estimates upon this corrected variance covariance matrix. We 
 implemented two OLS methods: 
    + **linear OLS regressions** 
    + **quadratic OLS regressions**
 - **Robust regressions regression** (R package `robustbase`,
 function `lmrob`, Maechler et al. 2020). We implemented MM-type regressions (hereafter called
 robust regressions) based on iteratively reweighted least squares since these types 
 of regressions are less sensitive to outliers than ordinary least square 
 regressions (and we do have outliers in INVACOST!) (Yohai 1987, Koller and 
 Stahel 2011). In addition, this method estimates standard errors robust to heteroskedasticity and autocorrelation as described in Croux et al. 2003. *Thanks 
 Andrew Kramer for this addition*. Likewise to OLS regressions, we implemented 
 two methods:
    + **Linear robust regressions** 
    + **quadratic robust regressions**
 - **Multivariate adaptive regression splines** (Multivariate Adaptive Regression 
 Splines, MARS, R package `earth`, function `earth`, Milborrow 2018). The MARS 
 model is a non-parametric regression method which automatically models
 nonlinearities, using Generalized Cross-Validation to avoid overfitting 
 (Friedman 1991, Hastie et al. 2009). The default parameters are implemented in
 order to follow Friedman's default, as described in 
 [Milborrow (2019a).](http://www.milbo.org/doc/earth-notes.pdf)
 We account for heteroskedasticity by
 fitting a linear model on the residuals. This linear model is fitted by 
 Iteratively Reweighting Least Squares. Note, however, that we have enough
 data to only approximately model variance, as explained in 
 [Milborrow (2019b)](http://www.milbo.org/doc/earth-varmod.pdf). Therefore, MARS
 models will have more uncertainty in the prediction intervals than in the
 predictions themselves.
 - **Generalized additive models** (Generalized Additive Models, GAM, R package
 `mgcv`, function `gam`, Wood et al. 2016). GAM models are automatic flexible statistical methods 
 used to identify and characterize nonlinear regression effects 
 (Hastie et al. 2009).
 The GAM model will also show non-linear patterns in cost trends over 
 time. To account for heteroskedasticity, we used a
 location-scale method which consists in fitting two GAMs, one for the average
 trend and one for the standard deviation. We used a simple Gaussian location
 scale family because, likewise to GAMs, we have  have enough
 data to only approximately model variance. 
 - **Quantile regressions** (R package `quantreg`, Koenker et al. 2020).
 Contrary to previous models, 
 quantile regressions do not try to estimate the average value, they estimate
 a specific quantile. In the package we chose quantiles 0.1 (lower boundary
 of annual costs), 0.5 (median cost value) and 0.9 (upper boundary of annual costs).

**References:**

Andrews DWK (1991), Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimation. _Econometrica_, *59*, 817–858.

Croux, C., Dhaene, G. and Hoorelbeke, D. (2003) Robust standard errors for robust estimators, _Discussion Papers Series 03.16_, K.U. Leuven, CES.

Friedman, J. H. (1991). "Multivariate Adaptive Regression Splines". _The Annals of Statistics._ *19* (1): 1–67.

Hastie T, Tibshirani R, Friedman J. (2009)  The elements of statistical learning: data mining, inference, and prediction. Springer, New York City, USA

Koenker, R. quantreg: Quantile Regression. R package version 5.61. Available at 
http://CRAN.R-project.org/package=quantreg (2020). 

Koller, M. and Stahel, W.A. (2011) Sharpening Wald-type inference in robust regression for small samples. Computational _Statistics & Data Analysis_ *55*(8), 2504–2515

Maechler M, Rousseeuw P, Croux C, Todorov V, Ruckstuhl A, Salibian-Barrera M, Verbeke T, Koller M, Eduardo LT,  Conceicao and di Palma MA (2020). robustbase: Basic Robust Statistics R package version 0.93-6. URL http://CRAN.R-project.org/package=robustbase

Milborrow, S. earth: Multivariate Adaptive regression Splines, R package version 4.6. 3 (2018).

Milborrow S. (2019a) Notes   on   earth   package.   Vignettes   of   the R package ‘earth’, http://www.milbo.org/doc/earth-notes.pdf

Milborrow S. (2019b) Variance models in earth.   Vignettes   of   the R package ‘earth’, http://www.milbo.org/doc/earth-varmod.pdf

Wood, S.N., N. Pya and B. Saefken (2016), Smoothing parameter and model selection for general smooth models. _Journal of the American Statistical Association_ *111*, 1548-1575 

Yohai, V., Stahel, W.A. and Zamar, R. (1991) A procedure for robust estimation and inference in linear regression; in Stahel and Weisberg (eds), _Directions in Robust Statistics and Diagnostics, Part II_, Springer, New York, 365–374

Zeileis A (2004). “Econometric Computing with HC and HAC Covariance Matrix Estimators.” _Journal of Statistical Software_, *11*(10), 1-17.

Zeileis A, Hothorn T (2002). Diagnostic Checking in Regression Relationships. _R News_ *2*(3), 7-10. URL https://CRAN.R-project.org/doc/Rnews/

**A few remarks:**

Paying attention to the statistical robustness of the model is important. 
However, remember that even if we had found a model that has an ideal fit to the
data, with no statistical violations whatsoever, we should absolutely not 
consider the predictions as accurate values of the annual costs of IAS, because 
of the assumption that there is a substantial part of costs that have not been
estimated or reported in INVACOST. The usefulness of these models is to 
investigate whether the costs are increasing, stabilizing, or decreasing, 
and how these trends changed over time, and to have an idea of the order of 
magnitude of annual IAS costs for different depending on time. 

Therefore, remember that the major uncertainty we have on estimated cost values
does not necessarily come from statistical robustness but rather from the 
unknown missing part of data.

It may not seem critical at this stage to have perfect statistics as long as 
the different methods do converge in their results. This is the general 
philosophy of fitting multiple models here, which is called an ensemble 
modelling procedure: compare if different methods converge in their results, 
so we have confidence that the result we observe is not a statistical artifact. 


Notwithstanding, we suggest to take time to carefully inspect your models, as 
we illustrate in the following sections.

## Model fitting

The function called `costTrendOverTime` will fit all models automatically. We 
can also provide several parameters such as 

- starting year (`minimum.year`): defaults to 1960
- ending year (`maximum.year`): defaults to 2017
- cost transformation (`cost.transf`): by default, a log10 transformation will
be applied
- costs in millions (`in.millions`): by default, costs are transformed in 
millions so numbers are easier to read
- threshold (`incomplete.year.threshold`) and/or weights 
(`incomplete.year.weights`) for incomplete years
- number of parameters for GAM (dimension basis `gam.k`) and MARS (number of
model terms `mars.nprune`). **We suggest you should not alter these parameters**
- the function will conveniently print the annual cost value estimated by
all models for a single year, usually the last year. You can change this by
defining `final.year` (defaults to 2017). Do not worry, values are estimated
for all years, this is mostly to provide a summary inspection in the console. 


In following example we have decided to exclude the five most recent years 
because they are likely to be the least complete years and they also contain 
obvious outliers as you will see on the graphs. You could also decide to 
manually exclude specific outliers by setting their weights to zero.

Here is an example in action:
```{r models}
global.trend <- costTrendOverTime(
  db.over.time, # The EXPANDED database
  minimum.year = 1970, 
  maximum.year = 2020,
  incomplete.year.threshold = 2015, 
  incomplete.year.weights = NULL)

# Let's see the results in the console
global.trend
```


## Model plotting


We can now look at the shape of each model with the `plot` function, which once
again does ggplot2 stuff internally in INVACOST:

```{r models2, fig.height=7, fig.width=10}
plot(global.trend)
```

We can see that all models generally converged in their predictions, suggesting
that the global costs of biological invasions have increased over the past
50 years. Different models suggest different patterns, as illustrated by 
the linear vs. quadratic models, the GAM and MARS models.
The trend illustrated by the MARS model is non-monotonous, suggesting a decrease
between 2000 and 2010. This apparent decrease provides insight into our data.
It may either indicate an actual decrease pattern in global invasion costs,
an illustration of the high dispersion of costs after 2000, or the 
incompleteness of data after 2000. Given our prior assumptions, we may hypothesise
that the two latter hypotheses are more probable than the former one. 

**Important** Note that error bands for MARS are 95% prediction intervals, whereas
for all other models they are 95% confidence intervals. Indeed, we cannot estimate
confidence intervals for MARS models.

Quantile regressions indicate a median (quantile 0.5) lower than the linear regression,
suggesting that most years have a lower-than-average cost of invasions, and a 
few years have very high costs. The 0.1 and 0.9 quantiles have diverging trends,
suggesting that the amplitude of costs increases over time (more discrepancy
between high-cost and low-cost years).

Remember to check your model summaries before going into more interpretations.
Some models may not be significant.


## Inspecting model outputs

We can access the content of the output object with
```{r models3, cache=TRUE}
str(global.trend)
```

There are several elements in the output object:

- `cost.data` contains total annual costs per year, upon which models were fitted
- `parameters` contains the parameters used to run the function 
- `fitted.models` contains all the objects of the fitted models. You can 
access models individually from here, look at the parameters, etc.
- `estimated.annual.costs` contains cost values predicted by all models for
each year, with confidence intervals
- `gam.predicted.variance` contains the predicted variance values for the
location-scale GAM model
- `model.summary` contains useful statistical information about models: r-squared,
adjusted r-squared, terms, significance, errors, etc.
- `RMSE` contains the root mean square error of all models, both for the 
calibration data only and for all data points
- `final.year.cost` is the cost value predicted by models for `final.year`

## How to  evaluate models?

We provide an example here where we rely on the different assumptions stated 
above.

First, we can look at model RMSE:

```{r models4}
global.trend$RMSE
```

Overall, both MARS models provide a closer fit to data points than 
other models. **Remember that RMSE is irrelevant for quantile regression
because it does not seek to fit the average trend.**

Hence, purely from a statistical point of view, we would tend to prioritize 
MARS models over models. However, remember that the MARS model illustrated
the uncertain behaviour of our data after 2000, and we may decide that,
based on our a-priori assumptions, this is not the most adequate model, and
we will also include the other models (who all have similar RMSE) in our predictions.


Now, some models may seem to have good fit but may not be significant. This
is highly critical especially for data-poor subsets of INVACOST. To verify this,
inspect the model summaries:

```{r models8}
global.trend$model.summary
```

This is quite long because of the many models we fitted! Inspecting these
outputs requires some statistical knowledge, so do not hesitate to read the
help files and papers mentioned in the **Models included** section.

If we start reading from the top, we can see that for OLS regressions, 
coefficients of the linear model are significant, but coefficients of the
quadratic model are not! So we should exclude this model from further analysis.

Looking at robust regressions, coefficients seem significant for both linear
and quadratic terms, and the model outputs also indicate us that some outliers
were found in both cases (their weight was set to zero). This is useful if your
dataset has a lot of outliers!

The GAM output states that both the mean and sd model were significant. It is 
more difficult to interpret GAMs solely based on this output, and you should
probably inspect model residuals visually etc. However, remember that we probably
do not have enough data to fit adequate GAMs, so be cautious with the interpretation.

The MARS output illustrates the different hinge functions. We can see the
years that serve as "breaking" point in the model, as well as the coefficients
of slopes after these years. It also shows the coefficients used to measure 
model performance, such as the Generalized Cross-Validation (GCV) which is the
residual sum of squares penalized by the effective number of model parameters,
or the GRSq, which is the R² normalizing the GCV (i.e., the higher the GRSq,
the better it is, and if you have a negative GRSq, it is very bad news). For more
information, see sections 13.6 and 13.11 in the 
[earth notes](http://www.milbo.org/doc/earth-notes.pdf).


## Including model summary in your paper

It may be difficult to report these vastly different model summaries in your
paper, so we have made a convenient function to summarize the important 
aspects of model summaries into a single table. You can then write this table
as a CSV file for example, and format it to include in your paper.

```{r models8.1}
summarized.summary <- prettySummary(global.trend)

summarized.summary
```



## Customising graphs



Customising plots for the modelling approach similar to the raw cost approach: 
there are two options. 


- The first one is to use the 
standard ggplot produced by the package and adding things or changing 
parameters. This method is easy to implement but you cannot change everything
(e.g. adjust the colors/shapes of points is not possible). This is what we
will see here. See the help here: `?plot.invacost.trendcost`

- The second one is to make your own ggplot from the output object. It is 
more difficult to implement if you are not familiar with graphs in R - but it
will be fully customisable. Take a look at the scripts from our main paper 
(`link to be added when available ¯\_(ツ)_/¯`) to see how to that.




# Simple customisation

There are two base plots provided with the package; you have already seen the 
default, and here is another one where all models are on a single facet:

```{r models5}
plot(global.trend,
     plot.type = "single")
```


Remember that we found that the OLS quadratic model was not significant?

We can exclude it from model outputs:


```{r models52, fig.width = 16, fig.height = 9}
plot(global.trend,
     models = c("ols.linear", "robust.linear", "robust.quadratic", "gam",
    "mars", "quantile"))
```


# Complex customisation

Likewise to the raw cost approach, if you want to customise ggplot parameters,
you have to set `graphical.parameters = "manual"`.

```{r models6, cache=TRUE}
# Store the plot in object p2 to customize it afterwards
p2 <- plot(global.trend,
           graphical.parameters = "manual")

# Show the graph in its initial state
p2
```

Ugly isn't it? That's mostly because the y scale is not in log10 scale.

You can now set all parameters by yourself; here is a starting point:
```{r models7, cache=TRUE}
# Customize p2 now
p2 <- p2 +
  xlab("Year") + 
  ylab("Average annual cost of invasions in US$ millions") +
  scale_x_continuous(breaks = raw.costs$year.breaks) + # X axis breaks
  theme_bw() + # Minimal theme
  scale_y_log10(breaks = 10^(-15:15), # y axis in log 10 with pretty labels
                labels = scales::comma) +
  annotation_logticks(sides = "l") # log10 tick marks on y axis

# Let's see how it goes
p2
```

Tadaaam!

# Example on a specific subset: mammals of North America

This is just an illustration to show you how to make it work on a subset of the
database. We are not going to analyse it in details.

We assume here that you have run the code on the first sections of this 
tutorial: database filtering and completeness.

First, let's inspect the geographic regions of INVACOST:
```{r example1.1}
unique(invacost$Geographic_region)
```

There are seven different regions in INVACOST, and sometimes cost are spread over 
different regions. Indeed, cost estimates in publications and reports often
correspond to data aggregated over several regions, several taxa, several types
of cost etc. Most of the time, it is not possible to 
split these costs into their respective subsets. Therefore, we have to omit them
if we want to focus on a single region. Here, we focus on North America only:

```{r example1.2}
invacost.NA <- invacost[which(invacost$Geographic_region == "North America"), ]

# Number of rows
nrow(invacost.NA)
```

We have `r nrow(invacost.NA)` lines in the North America subset of INVACOST. 

```{r example1.3}
# Let's see the content of the Class column
unique(invacost.NA$Class)
# Subset the NA INVACOST database
invacost.NA.mammals <- invacost.NA[which(invacost.NA$Class == "Mammalia"), ]

# Number of rows
nrow(invacost.NA.mammals)
```

Once again, there are studies involving multiple taxa, and here we focus only on
mammals.

There are only 63 rows in this subset, which may not be 
sufficient to run the predictive approach. Let's confirm this by starting with
the raw cost approach:


```{r example1.4}
# Expand the subset
NAmammals.over.time <- expandYearlyCosts(invacost.NA.mammals,
                                         startcolumn = "Probable_starting_year_low_margin",
                                         endcolumn = "Probable_ending_year_low_margin")


raw.NAmammals <- calculateRawAvgCosts(NAmammals.over.time,
                                    minimum.year = 1970)

raw.NAmammals

plot(raw.NAmammals)
```

Indeed, looking at the graph it would be ill-advised to calibrate models on this
subset of INVACOST (feel free to try it!).
We should rather focus on the cumulative cost over time, 
which in our case amounts to 
US$ `r scales::comma(raw.NAmammals$average.total.cost$total_cost)` millions for 
the 1970-2017 time period.


# Example on many subsets: all taxons/species in the database

This is a more complex situation where we want to derive a single estimate for 
all species/taxon in the database.

First, we need to inspect the taxonomic fields of the database to decide whether
we want to apply changes before running the script.

```{r allsp1}
# Here we just show the first 25
unique(invacost$Species)[1:25]
```

As you can see, there are many cases where multiple species are studied together.
These cases will be difficult to implement/analyse, but we can decide to merge
some of them together. For example, rats (genus *Rattus*) and mice (genus *Mus*)
have been often analysed together, and we could decide to merge them in a single
group:

```{r allsp2}
# First we create new columns in character format to avoid factor errors in R
invacost$sp.list <- as.character(invacost$Species)
invacost$genus.list <- as.character(invacost$Genus)

# Second, we merge Rattus and Mus together in a single group in these columns
# Species column
invacost$sp.list[which(invacost$Genus == "Rattus" | invacost$Genus == "Mus")] <- "Rattus spp./Mus spp."
invacost$sp.list[which(invacost$Species %in% c("Rattus sp./Mus sp.", 
                                               "Mus musculus/Rattus rattus",
                                               "Mus musculus/Rattus norvegicus",
                                               "Mus sp./Rattus sp."))] <- "Rattus spp./Mus spp."
# Genus column
invacost$genus.list[which(invacost$sp.list == "Rattus spp./Mus spp.")] <- "Rattus/Mus"
```

We can also do that for other taxa; here are the corrections we applied for the
main paper:

```{r allsp3}
invacost$sp.list[which(invacost$Genus == "Aedes")] <- "Aedes spp."
invacost$sp.list[which(invacost$Genus == "Felis/Rattus")] <- "Felis catus/Rattus spp."
invacost$sp.list[which(invacost$Genus == "Oryctolagus/Rattus")] <- "Oryctolagus spp./Rattus spp." 
invacost$sp.list[which(invacost$Genus == "Canis")] <- "Canis lupus spp."
```

Now that our taxon group list is set up, we still need to create a unique identifier 
for each taxon group. Indeed, if we use directly the `Species` column, then
all taxa that have the generic name *Diverse/Unspecified* will be considered 
in the same group. However, even if species names were unspecified, we still 
have information at high taxonomic levels (e.g., mammals, plants, etc.). 
Therefore, we will use all the taxonomic information to make sure that we do not
mix costs from e.g. plants with costs of mammals even when the species is 
marked as *Diverse/Unspecified*.

So we will create a 
unique identifier which integrates taxonomic data to avoid mixing together 
different kingdoms/phyla/classes etc.

```{r allsp4}
# Unique identifier
invacost$unique.sp.id <- do.call("paste", invacost[, c("Kingdom", "Phylum", "Class", "Family", "genus.list", "sp.list")])
```

Finally, we will write a loop that will cycle through all these unique groups,
and for each group, calculate the raw cumulative cost and average annual cost
for the 1970-2017 time period. 

```{r allsp5, warning=FALSE, cache = TRUE}
# First we expand the database
db.over.time <- expandYearlyCosts(invacost,
                                  startcolumn = "Probable_starting_year_low_margin",
                                  endcolumn = "Probable_ending_year_low_margin")


# Then we prepare a data.frame in which we will store our results
species.summary <- data.frame()
# We will cycle the loop through all unique identifiers
for(sp in unique(db.over.time$unique.sp.id))
{
  # We subset the database for our current species
  cur.db <- db.over.time[which(db.over.time$unique.sp.id %in% sp), ]
  
  # We apply the raw cost function
  cur.raw <- calculateRawAvgCosts(cur.db, minimum.year = 1970)
  
  
  # And from the cur.raw object we extract the specific information we are looking for
  species.summary <- rbind.data.frame(species.summary,
                                      data.frame(
                                        Kingdom = cur.db$Kingdom[1],
                                        Phylum = cur.db$Phylum[1],
                                        Class = cur.db$Class[1],
                                        Family = cur.db$Family[1],
                                        Genus = cur.db$Genus[1],
                                        Species = cur.db$sp.list[1],
                                        Average.annual.cost = cur.raw$average.total.cost$annual_cost,
                                        Cumulated.cost = cur.raw$average.total.cost$total_cost,
                                        Number.estimates = cur.raw$average.total.cost$number_estimates,
                                        Number.year.values = cur.raw$average.total.cost$number_year_values
                                      ))
}

# To make the summary dataframe nicer, we can sort by cost to have the highest groups first
species.summary <- species.summary[order(species.summary$Cumulated.cost, decreasing = TRUE), ]


# Have a look at the first groups
species.summary[1:10, ]
```

Of course, many lines in this table are not interesting because they correspond 
to all studies covering multiple taxa. Notwithstanding, we can see that the 
winners are mosquitoes with a cumulated cost of US$ 158,622 million for 1970-
2017, based on 208 cost estimates in total.

For a more detailed example, please look at the scripts we provided with the
main paper here: `link to be added when available ¯\_(ツ)_/¯`.


# Improving the package

If something is not clear, or missing, please send me a detailed question by 
mail (leroy.boris@gmail.com). However, remember that we need to find a good balance
between generalisability and specificity: not enough parameters and users are not
happy; too many parameters and users are lost in the function usage. Therefore,
if you have a very specific request that will not be useful to other users, do
not hesitate to duplicate the source code and adapt the function to your needs.
On the contrary, if you think of a new thing that could be beneficial to many
users, please do not hesitate and become an official contributor to the
package!

# Citation

If you found the package and/or the tutorial useful, please do not hesitate to
cite the package (in addition to the papers) as an acknowledgement for the
time spent in writing the package and this tutorial. Like all R packages, 
to know how to cite it, type:
```{r i4, cache = TRUE}
citation("invacost")
```


